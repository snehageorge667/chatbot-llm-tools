from backend.llm.llm_client import get_llm_response

llm_node = {
    "run": get_llm_response
}
